{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asymmetric Learned Image Compression with Multi-Scale Residual Block, Importance Map, and Post-Quantization Filtering\n",
    "\n",
    "## Design Credit Project \n",
    "\n",
    "    Ayush Abrol B20AI052\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18 14:02:10.939717: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-18 14:02:10.939774: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-18 14:02:10.939808: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-18 14:02:10.948610: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-18 14:02:12.349802: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import range_coder\n",
    "import pywt\n",
    "from keras.datasets import mnist\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "import tensorflow_compression as tfc\n",
    "import math\n",
    "import time\n",
    "import scipy.special\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "from absl import app\n",
    "from absl.flags import argparse_flags\n",
    "from PIL import Image\n",
    "\n",
    "from range_coder import RangeEncoder, RangeDecoder, prob_to_cum_freq\n",
    "import tensorflow_probability as  tfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ayushabrol/.local/lib/python3.10/site-packages/tensorflow/python/compat/v2_compat.py:108: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.14.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tensorflow_probability.python.distributions' from '/home/ayushabrol/.local/lib/python3.10/site-packages/tensorflow_probability/python/distributions/__init__.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfd = tfp.distributions \n",
    "tfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_size(input_file):\n",
    "  I = Image.open(input_file)\n",
    "  I_array = np.array(I)\n",
    "  height_ori, width_ori, _ = np.shape(I_array)\n",
    "  height = (height_ori // 64) * 64 if height_ori % 64 == 0 else (height_ori // 64 + 1) * 64\n",
    "  width = (width_ori // 64) * 64 if width_ori % 64 == 0 else (width_ori // 64 + 1) * 64\n",
    "  top_end = (height - height_ori) // 2\n",
    "  left_end = (width - width_ori) // 2\n",
    "  \n",
    "  top_end = (height - height_ori) // 2\n",
    "  left_end = (width - width_ori) // 2\n",
    "  real_height_start = top_end\n",
    "  real_height_end = top_end + height_ori\n",
    "  real_width_start = left_end\n",
    "  real_width_end = left_end + width_ori\n",
    "  I_array_padded = np.zeros((1,height,width,3), np.uint8)\n",
    "  I_array_padded[0,top_end:top_end+height_ori, left_end:left_end+width_ori,:]=I_array\n",
    "  print('height_pad:', height, 'width_pad:', width)\n",
    "  \n",
    "  return I_array_padded,(real_height_start, real_height_end, real_width_start, real_width_end, height, width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_png(filename):\n",
    "  \"\"\"Loads a PNG image file.\"\"\"\n",
    "  string = tf.read_file(filename)\n",
    "  image = tf.image.decode_image(string, channels=3)\n",
    "  image = tf.cast(image, tf.float32)\n",
    "  image /= 255\n",
    "  return image\n",
    "\n",
    "def quantize_image(image):\n",
    "  image = tf.round(image * 255)\n",
    "  image = tf.saturate_cast(image, tf.uint8)\n",
    "  return image\n",
    "\n",
    "def write_png(filename, image):\n",
    "  \"\"\"Saves an image to a PNG file.\"\"\"\n",
    "  image = quantize_image(image)\n",
    "  string = tf.image.encode_png(image)\n",
    "  return tf.write_file(filename, string)\n",
    "\n",
    "\n",
    "def load_image(filename):\n",
    "  \"\"\"Loads a PNG image file.\"\"\"\n",
    "\n",
    "  string = tf.read_file(filename)\n",
    "  image = tf.image.decode_image(string, channels=3)\n",
    "  image = tf.cast(image, tf.float32)\n",
    "  image /= 255\n",
    "  return image\n",
    "\n",
    "def save_image(filename, image):\n",
    "  \"\"\"Saves an image to a PNG file.\"\"\"\n",
    "\n",
    "  image = tf.clip_by_value(image, 0, 1)\n",
    "  image = tf.round(image * 255)\n",
    "  image = tf.cast(image, tf.uint8)\n",
    "  string = tf.image.encode_png(image)\n",
    "  return tf.write_file(filename, string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residualblock(tensor, num_filters, scope=\"residual_block\"):\n",
    "  \"\"\"Builds the residual block\"\"\"\n",
    "  with tf.compat.v1.variable_scope(scope):\n",
    "    with tf.compat.v1.variable_scope(\"conv0\"):\n",
    "      layer = tfc.SignalConv2D(\n",
    "        num_filters//2, (1,1), corr=True, strides_down=1, padding=\"same_zeros\",\n",
    "        use_bias=True, activation=tf.nn.relu, name='signal_conv2d')\n",
    "      output = layer(tensor)\n",
    "\n",
    "    with tf.compat.v1.variable_scope(\"conv1\"):\n",
    "      layer = tfc.SignalConv2D(\n",
    "        num_filters//2, (3,3), corr=True, strides_down=1, padding=\"same_zeros\",\n",
    "        use_bias=True, activation=tf.nn.relu, name='signal_conv2d')\n",
    "      output = layer(output)\n",
    "\n",
    "    with tf.compat.v1.variable_scope(\"conv2\"):\n",
    "      layer = tfc.SignalConv2D(\n",
    "        num_filters, (1,1), corr=True, strides_down=1, padding=\"same_zeros\",\n",
    "        use_bias=True, activation=None, name='signal_conv2d')\n",
    "      output = layer(output)\n",
    "      \n",
    "    tensor = tensor + output\n",
    "       \n",
    "  return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residualblock_kenal(tensor, num_filters, kernel_size =3, scope=\"residual_block\"):\n",
    "  \"\"\"Builds the residual block\"\"\"\n",
    "  \n",
    "  with tf.compat.v1.variable_scope(scope):\n",
    "    with tf.compat.v1.variable_scope(\"conv0\"):\n",
    "      layer = tfc.SignalConv2D(\n",
    "        num_filters//2, (1,1), corr=True, strides_down=1, padding=\"same_zeros\",\n",
    "        use_bias=True, activation=tf.nn.relu, name='signal_conv2d')\n",
    "      output = layer(tensor)\n",
    "\n",
    "    with tf.compat.v1.variable_scope(\"conv1\"):\n",
    "      layer = tfc.SignalConv2D(\n",
    "        num_filters//2, (kernel_size,kernel_size), corr=True, strides_down=1, padding=\"same_zeros\",\n",
    "        use_bias=True, activation=tf.nn.relu, name='signal_conv2d')\n",
    "      output = layer(output)\n",
    "\n",
    "    with tf.compat.v1.variable_scope(\"conv2\"):\n",
    "      layer = tfc.SignalConv2D(\n",
    "        num_filters, (1,1), corr=True, strides_down=1, padding=\"same_zeros\",\n",
    "        use_bias=True, activation=None, name='signal_conv2d')\n",
    "      output = layer(output)\n",
    "      \n",
    "    tensor = tensor + output\n",
    "       \n",
    "  return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Multiply_resblock(tensor, num_filters, kernel_size =3, scope=\"multiply_residual_block\"):\n",
    "  \"\"\"Builds the residual block\"\"\"\n",
    "  with tf.compat.v1.variable_scope(scope):\n",
    "    trunk_branch_3 = residualblock_kenal(tensor, num_filters, 3,scope=\"trunk_RB_3_3\")\n",
    "    trunk_branch_5 = residualblock_kenal(tensor, num_filters, 5,scope=\"trunk_RB_5_5\")\n",
    "    \n",
    "    \n",
    "    input_1 = tf.concat([trunk_branch_3, trunk_branch_5], axis=3)\n",
    "    input_2 = tf.concat([trunk_branch_5, trunk_branch_3], axis=3)\n",
    "    \n",
    "    with tf.compat.v1.variable_scope(\"input_1_conv_1x1\"):\n",
    "      layer = tfc.SignalConv2D(\n",
    "        num_filters, (1,1), corr=True, strides_down=1, padding=\"same_zeros\",\n",
    "        use_bias=True, activation=tf.nn.relu, name='signal_conv2d')\n",
    "      input_1 = layer(input_1)\n",
    "    \n",
    "    \n",
    "    with tf.compat.v1.variable_scope(\"input_2_conv_1x1\"):\n",
    "      layer = tfc.SignalConv2D(\n",
    "        num_filters, (1,1), corr=True, strides_down=1, padding=\"same_zeros\",\n",
    "        use_bias=True, activation=tf.nn.relu, name='signal_conv2d')\n",
    "      input_2 = layer(input_2)\n",
    "    \n",
    "    \n",
    "    second_trunk_branch_3 = residualblock_kenal(input_1, num_filters, 3,scope=\"second_trunk_RB_3_3\")\n",
    "    second_trunk_branch_5 = residualblock_kenal(input_2, num_filters, 5,scope=\"second_trunk_RB_5_5\")\n",
    "    \n",
    "    third_input = tf.concat([second_trunk_branch_3, second_trunk_branch_5], axis=3)\n",
    "    \n",
    "    with tf.compat.v1.variable_scope(\"conv_1x1\"):\n",
    "      layer = tfc.SignalConv2D(\n",
    "        num_filters, (1,1), corr=True, strides_down=1, padding=\"same_zeros\",\n",
    "        use_bias=True, activation=None, name='signal_conv2d')\n",
    "      output = layer(third_input)\n",
    "    tensor = tensor + output\n",
    "  return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NonLocalAttentionBlock(input_x, num_filters, scope=\"NonLocalAttentionBlock\"):\n",
    "  \"\"\"Builds the non-local attention block\"\"\"\n",
    "  with tf.compat.v1.variable_scope(scope):\n",
    "    trunk_branch = residualblock(input_x, num_filters, scope=\"trunk_RB_0\")\n",
    "    trunk_branch = residualblock(trunk_branch, num_filters, scope=\"trunk_RB_1\")\n",
    "    trunk_branch = residualblock(trunk_branch, num_filters, scope=\"trunk_RB_2\")\n",
    "    \n",
    "    attention_branch = residualblock(input_x, num_filters, scope=\"attention_RB_0\")\n",
    "    attention_branch = residualblock(attention_branch, num_filters, scope=\"attention_RB_1\")\n",
    "    attention_branch = residualblock(attention_branch, num_filters, scope=\"attention_RB_2\")\n",
    "\n",
    "    with tf.compat.v1.variable_scope(\"conv_1x1\"):\n",
    "      layer = tfc.SignalConv2D(\n",
    "        num_filters, (1,1), corr=True, strides_down=1, padding=\"same_zeros\",\n",
    "        use_bias=True, activation=None, name='signal_conv2d')\n",
    "      attention_branch = layer(attention_branch)\n",
    "    attention_branch = tf.sigmoid(attention_branch)\n",
    "\n",
    "  tensor = input_x + tf.multiply(attention_branch, trunk_branch)\n",
    "  return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis_transform(tensor, num_filters):\n",
    "  \"\"\"Builds the analysis transform.\"\"\"\n",
    "\n",
    "  kernel_size = 3\n",
    "  #Use three 3x3 filters to replace one 9x9\n",
    "  \n",
    "  with tf.compat.v1.variable_scope(\"analysis\"):\n",
    "\n",
    "    # Four down-sampling blocks\n",
    "    for i in range(4):\n",
    "      if i > 0:\n",
    "        # with tf.variable_scope(\"Block_\" + str(i) + \"_layer_0\"):\n",
    "          # layer = tfc.SignalConv2D(\n",
    "            # num_filters, (kernel_size, kernel_size), corr=True, strides_down=1, padding=\"same_zeros\",\n",
    "            # use_bias=True, activation=tf.nn.leaky_relu, name='signal_conv2d')\n",
    "          # tensor2 = layer(tensor)\n",
    "\n",
    "        # with tf.variable_scope(\"Block_\" + str(i) + \"_layer_1\"):\n",
    "          # layer = tfc.SignalConv2D(\n",
    "              # num_filters, (kernel_size, kernel_size), corr=True, strides_down=1, padding=\"same_zeros\",\n",
    "              # use_bias=True, activation=tf.nn.leaky_relu, name='signal_conv2d')\n",
    "          # tensor2 = layer(tensor2)\n",
    "        \n",
    "        # tensor = tensor + tensor2\n",
    "        tensor = Multiply_resblock(tensor, num_filters, kernel_size =3, scope=\"multiply_residual_block\"+str(i))\n",
    "\n",
    "\n",
    "      if i < 3:\n",
    "        with tf.compat.v1.variable_scope(\"Block_\" + str(i) + \"_shortcut\"):\n",
    "          shortcut = tfc.SignalConv2D(num_filters, (1, 1), corr=True, strides_down=2, padding=\"same_zeros\",\n",
    "                                      use_bias=True, activation=None, name='signal_conv2d')\n",
    "          shortcut_tensor = shortcut(tensor)\n",
    "\n",
    "        with tf.compat.v1.variable_scope(\"Block_\" + str(i) + \"_layer_2\"):\n",
    "          layer = tfc.SignalConv2D(\n",
    "              num_filters, (kernel_size, kernel_size), corr=True, strides_down=2, padding=\"same_zeros\",\n",
    "              use_bias=True, activation=tf.nn.leaky_relu, name='signal_conv2d')\n",
    "          tensor = layer(tensor)\n",
    "\n",
    "        with tf.compat.v1.variable_scope(\"Block_\" + str(i) + \"_layer_3\"):\n",
    "          layer = tfc.SignalConv2D(\n",
    "            num_filters, (kernel_size, kernel_size), corr=True, strides_down=1, padding=\"same_zeros\",\n",
    "            use_bias=True, activation=tf.nn.leaky_relu, name='signal_conv2d')\n",
    "          tensor = layer(tensor)\n",
    "          \n",
    "          tensor = tensor + shortcut_tensor\n",
    "\n",
    "        if i == 1:\n",
    "          #Add one NLAM\n",
    "          tensor = NonLocalAttentionBlock(tensor, num_filters, scope=\"NLAB_0\")\n",
    "          \n",
    "\n",
    "      else:\n",
    "        with tf.compat.v1.variable_scope(\"Block_\" + str(i) + \"_layer_2\"):\n",
    "          layer = tfc.SignalConv2D(\n",
    "            num_filters, (kernel_size, kernel_size), corr=True, strides_down=2, padding=\"same_zeros\",\n",
    "            use_bias=False, activation=None, name='signal_conv2d') \n",
    "          tensor_out = layer(tensor)\n",
    "          \n",
    "          \n",
    "        with tf.compat.v1.variable_scope(\"Heatmap\"):\n",
    "          layer = tfc.SignalConv2D(\n",
    "            num_filters, (kernel_size, kernel_size), corr=True, strides_down=2, padding=\"same_zeros\",\n",
    "            use_bias=True, activation=tf.nn.relu, name='signal_conv2d') \n",
    "          tensor_heatin = layer(tensor)\n",
    "          tensor_heatmap = residualblock(tensor_heatin,num_filters)\n",
    "          tensor_heatmap = residualblock(tensor_heatmap,num_filters)\n",
    "          tensor_heatmap = residualblock(tensor_heatmap,num_filters)\n",
    "          tensor_heatmap = tensor_heatin + tensor_heatmap\n",
    "          tensor_heatmap = tf.math.tanh(tensor_heatmap)\n",
    "          tensor_heatmap = tf.nn.softsign(tensor_heatmap)\n",
    "\n",
    "        #Add one NLAM\n",
    "        tensor_out = NonLocalAttentionBlock(tensor_out, num_filters, scope=\"NLAB_1\")\n",
    "        tensor = tensor_heatmap*tensor_out\n",
    "\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper_analysis(tensor, num_filters):\n",
    "  \"\"\"Build the analysis transform in hyper\"\"\"\n",
    "\n",
    "  with tf.compat.v1.variable_scope(\"hyper_analysis\"):\n",
    "    with tf.compat.v1.variable_scope(\"layer_0\"):\n",
    "      layer = tfc.SignalConv2D(\n",
    "        num_filters, (3, 3), corr=True, strides_down=1, padding=\"same_zeros\",\n",
    "        use_bias=True, activation=tf.nn.leaky_relu, name='signal_conv2d')\n",
    "      tensor = layer(tensor)\n",
    "\n",
    "    #One 5x5 is replaced by two 3x3 filters     \n",
    "    with tf.compat.v1.variable_scope(\"layer_1\"):\n",
    "      layer = tfc.SignalConv2D(\n",
    "        num_filters, (3, 3), corr=True, strides_down=1, padding=\"same_zeros\",\n",
    "        use_bias=True, activation=tf.nn.leaky_relu, name='signal_conv2d')\n",
    "      tensor = layer(tensor)\n",
    "\n",
    "    with tf.compat.v1.variable_scope(\"layer_2\"):\n",
    "      layer = tfc.SignalConv2D(\n",
    "        num_filters, (3, 3), corr=True, strides_down=2, padding=\"same_zeros\",\n",
    "        use_bias=True, activation=tf.nn.leaky_relu, name='signal_conv2d')\n",
    "      tensor = layer(tensor)\n",
    "\n",
    "    #One 5x5 is replaced by two 3x3 filters \n",
    "    with tf.compat.v1.variable_scope(\"layer_3\"):\n",
    "      layer = tfc.SignalConv2D(\n",
    "        num_filters, (3, 3), corr=True, strides_down=1, padding=\"same_zeros\",\n",
    "        use_bias=True, activation=tf.nn.leaky_relu, name='signal_conv2d')\n",
    "      tensor = layer(tensor)\n",
    "\n",
    "    with tf.compat.v1.variable_scope(\"layer_4\"):\n",
    "      layer = tfc.SignalConv2D(\n",
    "        num_filters, (3, 3), corr=True, strides_down=2, padding=\"same_zeros\",\n",
    "        use_bias=True, activation=None, name='signal_conv2d')\n",
    "      tensor = layer(tensor)\n",
    "\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesis_transform(tensor, num_filters):\n",
    "  \"\"\"Builds the synthesis transform.\"\"\"\n",
    "\n",
    "  kernel_size = 3\n",
    "  #Use four 3x3 filters to replace one 9x9\n",
    "  \n",
    "  with tf.variable_scope(\"synthesis\"):\n",
    "\n",
    "    # Four up-sampling blocks\n",
    "    for i in range(4):\n",
    "      if i == 0:\n",
    "        #Add one NLAM\n",
    "        tensor = NonLocalAttentionBlock(tensor, num_filters, scope=\"NLAB_0\")\n",
    "\n",
    "      if i == 2:\n",
    "        #Add one NLAM\n",
    "        tensor = NonLocalAttentionBlock(tensor, num_filters, scope=\"NLAB_1\")\n",
    "        \n",
    "      # with tf.variable_scope(\"Block_\" + str(i) + \"_layer_0\"):\n",
    "        # layer = tfc.SignalConv2D(\n",
    "          # num_filters, (kernel_size, kernel_size), corr=False, strides_up=1, padding=\"same_zeros\",\n",
    "          # use_bias=True, activation=tf.nn.leaky_relu, name='signal_conv2d')\n",
    "        # tensor2 = layer(tensor)\n",
    "\n",
    "      # with tf.variable_scope(\"Block_\" + str(i) + \"_layer_1\"):\n",
    "        # layer = tfc.SignalConv2D(\n",
    "          # num_filters, (kernel_size, kernel_size), corr=False, strides_up=1, padding=\"same_zeros\",\n",
    "          # use_bias=True, activation=tf.nn.leaky_relu, name='signal_conv2d')\n",
    "        # tensor2 = layer(tensor2)\n",
    "        # tensor = tensor + tensor2\n",
    "        tensor = Multiply_resblock(tensor, num_filters, kernel_size =3, scope=\"multiply_residual_block\"+str(i))\n",
    "\n",
    "\n",
    "      if i <3:\n",
    "        with tf.variable_scope(\"Block_\" + str(i) + \"_shortcut\"):\n",
    "\n",
    "          # Use Sub-Pixel to replace deconv.\n",
    "          shortcut = tfc.SignalConv2D(num_filters*4, (1, 1), corr=False, strides_up=1, padding=\"same_zeros\",\n",
    "                                      use_bias=True, activation=None, name='signal_conv2d')\n",
    "          shortcut_tensor = shortcut(tensor)\n",
    "          shortcut_tensor = tf.depth_to_space(shortcut_tensor, 2)\n",
    "\n",
    "        with tf.variable_scope(\"Block_\" + str(i) + \"_layer_2\"):\n",
    "\n",
    "          # Use Sub-Pixel to replace deconv.\n",
    "          layer = tfc.SignalConv2D(num_filters*4, (kernel_size, kernel_size), corr=False, strides_up=1, padding=\"same_zeros\",\n",
    "                                   use_bias=True, activation=tf.nn.leaky_relu, name='signal_conv2d')\n",
    "          tensor = layer(tensor)\n",
    "          tensor = tf.depth_to_space(tensor, 2)         \n",
    "          \n",
    "        with tf.variable_scope(\"Block_\" + str(i) + \"_layer_3\"):\n",
    "          layer = tfc.SignalConv2D(\n",
    "            num_filters, (kernel_size, kernel_size), corr=False, strides_up=1, padding=\"same_zeros\",\n",
    "            use_bias=True, activation=tf.nn.leaky_relu, name='signal_conv2d')\n",
    "          tensor = layer(tensor)\n",
    "          \n",
    "          tensor = tensor + shortcut_tensor\n",
    "\n",
    "      else:\n",
    "        with tf.variable_scope(\"Block_\" + str(i) + \"_layer_2\"):\n",
    "          \n",
    "          # Use Sub-Pixel to replace deconv.\n",
    "          layer = tfc.SignalConv2D(12, (kernel_size, kernel_size), corr=False, strides_up=1, padding=\"same_zeros\",\n",
    "                                   use_bias=True, activation=None, name='signal_conv2d')\n",
    "          tensor = layer(tensor)\n",
    "          tensor = tf.depth_to_space(tensor, 2)\n",
    "          \n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper_synthesis(tensor, num_filters):\n",
    "  \"\"\"Builds the hyper synthesis transform\"\"\"\n",
    "\n",
    "  with tf.compat.v1.variable_scope(\"hyper_synthesis\", reuse=tf.AUTO_REUSE):\n",
    "    #One 5x5 is replaced by two 3x3 filters\n",
    "    with tf.variable_scope(\"layer_0\"):\n",
    "      layer = tfc.SignalConv2D(\n",
    "        num_filters, (3, 3), corr=False, strides_up = 1, padding=\"same_zeros\",\n",
    "        use_bias=True, activation=tf.nn.leaky_relu, name='signal_conv2d')\n",
    "      tensor = layer(tensor)\n",
    "\n",
    "    with tf.compat.v1.variable_scope(\"layer_1\"):\n",
    "      layer = tfc.SignalConv2D(\n",
    "        num_filters, (3, 3), corr=False, strides_up = 2, padding=\"same_zeros\",\n",
    "        use_bias=True, activation=tf.nn.leaky_relu, name='signal_conv2d')\n",
    "      tensor = layer(tensor)\n",
    "\n",
    "    #One 5x5 is replaced by two 3x3 filters\n",
    "    with tf.compat.v1.variable_scope(\"layer_2\"):\n",
    "      layer = tfc.SignalConv2D(\n",
    "        num_filters*1.5, (3, 3), corr=False, strides_up = 1, padding=\"same_zeros\",\n",
    "        use_bias=True, activation=tf.nn.leaky_relu, name='signal_conv2d')\n",
    "      tensor = layer(tensor)\n",
    "\n",
    "    with tf.compat.v1.variable_scope(\"layer_3\"):\n",
    "      layer = tfc.SignalConv2D(\n",
    "        num_filters*1.5, (3, 3), corr=False, strides_up = 2, padding=\"same_zeros\",\n",
    "        use_bias=True, activation=tf.nn.leaky_relu, name='signal_conv2d')\n",
    "      tensor = layer(tensor)\n",
    "\n",
    "    with tf.compat.v1.variable_scope(\"layer_4\"):\n",
    "      layer = tfc.SignalConv2D(\n",
    "        num_filters*2, (3, 3), corr=False, strides_up = 1, padding=\"same_zeros\",\n",
    "        use_bias=True, activation=None, name='signal_conv2d')\n",
    "      tensor = layer(tensor)\n",
    "\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_conv2d(\n",
    "    inputs,\n",
    "    num_outputs,\n",
    "    kernel_shape, # [kernel_height, kernel_width]\n",
    "    mask_type, # None, \"A\" or \"B\",\n",
    "    strides=[1, 1], # [column_wise_stride, row_wise_stride]\n",
    "    padding=\"SAME\",\n",
    "    activation_fn=None,\n",
    "    weights_initializer=tf.keras.initializers.GlorotUniform(),\n",
    "    weights_regularizer=None,\n",
    "    biases_initializer=tf.zeros_initializer(),\n",
    "    biases_regularizer=None,\n",
    "    scope=\"masked\"):\n",
    "  \n",
    "  with tf.compat.v1.variable_scope(scope):\n",
    "    mask_type = mask_type.lower()\n",
    "    batch_size, height, width, channel = inputs.get_shape().as_list()\n",
    "\n",
    "    kernel_h, kernel_w = kernel_shape\n",
    "    stride_h, stride_w = strides\n",
    "\n",
    "    assert kernel_h % 2 == 1 and kernel_w % 2 == 1, \\\n",
    "      \"kernel height and width should be odd number\"\n",
    "\n",
    "    center_h = kernel_h // 2\n",
    "    center_w = kernel_w // 2\n",
    "\n",
    "    weights_shape = [kernel_h, kernel_w, channel, num_outputs]\n",
    "    weights = tf.get_variable(\"weights\", weights_shape,\n",
    "      tf.float32, weights_initializer, weights_regularizer)\n",
    "\n",
    "    if mask_type is not None:\n",
    "      mask = np.ones(\n",
    "        (kernel_h, kernel_w, channel, num_outputs), dtype=np.float32)\n",
    "\n",
    "      mask[center_h, center_w+1: ,: ,:] = 0.\n",
    "      mask[center_h+1:, :, :, :] = 0.\n",
    "\n",
    "      if mask_type == 'a':\n",
    "        mask[center_h,center_w,:,:] = 0.\n",
    "\n",
    "      weights *= tf.constant(mask, dtype=tf.float32)\n",
    "      tf.add_to_collection('conv2d_weights_%s' % mask_type, weights)\n",
    "\n",
    "    outputs = tf.nn.conv2d(inputs,\n",
    "        weights, [1, stride_h, stride_w, 1], padding=padding, name='outputs')\n",
    "    tf.add_to_collection('conv2d_outputs', outputs)\n",
    "\n",
    "    if biases_initializer != None:\n",
    "      biases = tf.get_variable(\"biases\", [num_outputs,],\n",
    "          tf.float32, biases_initializer, biases_regularizer)\n",
    "      outputs = tf.nn.bias_add(outputs, biases, name='outputs_plus_b')\n",
    "\n",
    "    if activation_fn:\n",
    "      outputs = activation_fn(outputs, name='outputs_with_fn')\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_parameter(tensor, inputs, num_filters, training):\n",
    "  \"\"\"tensor: the output of hyper autoencoder (phi) to generate the mean and variance\n",
    "     inputs: the variable needs to be encoded. (y)\n",
    "  \"\"\"\n",
    "  with tf.compat.v1.variable_scope(\"entropy_parameter\", reuse=tf.AUTO_REUSE):\n",
    "\n",
    "    half = tf.constant(.5)\n",
    "\n",
    "    if training:\n",
    "      noise = tf.random_uniform(tf.shape(inputs), -half, half)\n",
    "      values = tf.add_n([inputs, noise])\n",
    "      \n",
    "      \n",
    "\n",
    "    else: #inference\n",
    "      #if inputs is not None: #compress\n",
    "      values = tf.round(inputs)\n",
    "        \n",
    "\n",
    "    masked = masked_conv2d(values, num_filters*2, [5, 5], \"A\", scope='masked')\n",
    "    tensor = tf.concat([masked, tensor], axis=3)\n",
    "      \n",
    "\n",
    "    with tf.compat.v1.variable_scope(\"layer_0\"):\n",
    "      layer = tfc.SignalConv2D(\n",
    "          640, (1, 1), corr=True, strides_down=1, padding=\"same_zeros\",\n",
    "          use_bias=True, activation=tf.nn.leaky_relu)\n",
    "      tensor = layer(tensor)\n",
    "\n",
    "    with tf.compat.v1.variable_scope(\"layer_1\"):\n",
    "      layer = tfc.SignalConv2D(\n",
    "          640, (1, 1), corr=True, strides_down=1, padding=\"same_zeros\",\n",
    "          use_bias=True, activation=tf.nn.leaky_relu)\n",
    "      tensor = layer(tensor)\n",
    "\n",
    "    with tf.compat.v1.variable_scope(\"layer_2\"):\n",
    "      layer = tfc.SignalConv2D(\n",
    "          num_filters*9, (1, 1), corr=True, strides_down=1, padding=\"same_zeros\",\n",
    "          use_bias=False, activation=None)\n",
    "      tensor = layer(tensor)\n",
    "\n",
    "\n",
    "    #=========Gaussian Mixture Model=========\n",
    "    prob0, mean0, scale0, prob1, mean1, scale1, prob2, mean2, scale2 = \\\n",
    "             tf.split(tensor, num_or_size_splits=9, axis = 3)\n",
    "    scale0 = tf.abs(scale0)\n",
    "    scale1 = tf.abs(scale1)\n",
    "    scale2 = tf.abs(scale2)\n",
    "\n",
    "\n",
    "\n",
    "    probs = tf.stack([prob0, prob1, prob2], axis=-1)\n",
    "    probs = tf.nn.softmax(probs, axis=-1)\n",
    "  \n",
    "    # To merge them together\n",
    "    means = tf.stack([mean0, mean1, mean2], axis=-1)\n",
    "    variances = tf.stack([scale0, scale1, scale2], axis=-1)\n",
    "\n",
    "    # =======================================\n",
    "    ###cancel note\n",
    "    #Calculate the likelihoods for inputs\n",
    "    #if inputs is not None:\n",
    "    if training:\n",
    "\n",
    "      dist_0 = tfd.Normal(loc = mean0, scale = scale0, name='dist_0')\n",
    "      dist_1 = tfd.Normal(loc = mean1, scale = scale1, name='dist_1')\n",
    "      dist_2 = tfd.Normal(loc = mean2, scale = scale2, name='dist_2')\n",
    "\n",
    "      #=========Gaussian Mixture Model=========\n",
    "      likelihoods_0 = dist_0.cdf(values + half) - dist_0.cdf(values - half)\n",
    "      likelihoods_1 = dist_1.cdf(values + half) - dist_1.cdf(values - half)\n",
    "      likelihoods_2 = dist_2.cdf(values + half) - dist_2.cdf(values - half)\n",
    "\n",
    "      likelihoods = probs[:,:,:,:,0]*likelihoods_0 + probs[:,:,:,:,1]*likelihoods_1 + probs[:,:,:,:,2]*likelihoods_2\n",
    "\n",
    "      # =======REVISION: Robust version ==========\n",
    "      edge_min = probs[:,:,:,:,0]*dist_0.cdf(values + half) + \\\n",
    "                 probs[:,:,:,:,1]*dist_1.cdf(values + half) + \\\n",
    "                 probs[:,:,:,:,2]*dist_2.cdf(values + half)\n",
    "      \n",
    "      edge_max = probs[:,:,:,:,0]* (1.0 - dist_0.cdf(values - half)) + \\\n",
    "                 probs[:,:,:,:,1]* (1.0 - dist_1.cdf(values - half)) + \\\n",
    "                 probs[:,:,:,:,2]* (1.0 - dist_2.cdf(values - half))\n",
    "      likelihoods = tf.where(values < -254.5, edge_min, tf.where(values > 255.5, edge_max, likelihoods))\n",
    "\n",
    "      \n",
    "      likelihood_lower_bound = tf.constant(1e-6)\n",
    "      likelihood_upper_bound = tf.constant(1.0)\n",
    "      likelihoods = tf.minimum(tf.maximum(likelihoods, likelihood_lower_bound), likelihood_upper_bound)\n",
    "      \n",
    "    else:\n",
    "      #values = None\n",
    "      likelihoods = None\n",
    "        \n",
    "  return values, likelihoods, means, variances, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ayushabrol/.local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import compressai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress(input, output, num_filters, checkpoint_dir):\n",
    "\n",
    "    start = time.time()\n",
    "    # tf.set_random_seed(1)\n",
    "    # tf.reset_default_graph()\n",
    "      \n",
    "      \n",
    "      #with tf.device('/cpu:0'):\n",
    "        # Load input image and add batch dimension.\n",
    "        \n",
    "    #x = load_image(input)\n",
    "    #print(\"x shape is {}\".format(x.get_shape().as_list()))\n",
    "    images_info = get_image_size(input)\n",
    "    images_padded_numpy, size = images_info\n",
    "    print(\"the size is {}\".format(len(size)))\n",
    "    real_height_start, real_height_end, real_width_start, real_width_end, height, width = size\n",
    "    with tf.name_scope('Data'):\n",
    "      images_padded = tf.compat.v1.placeholder(tf.float32, shape=(1, height, width, 3), name='images_ori')\n",
    "      x = images_padded\n",
    "      x_shape = tf.shape(x)\n",
    "    y = analysis_transform(x, num_filters)\n",
    "\n",
    "    # Build a hyper autoencoder\n",
    "    z = hyper_analysis(y, num_filters)\n",
    "    # entropy_bottleneck = compressai.entropy_models.EntropyBottleneck(channels=num_filters)\n",
    "    entropy_bottleneck = tfc.entropy_models.PowerLawEntropyModel(2, alpha=0.01, bottleneck_dtype=None)\n",
    "    string = entropy_bottleneck.compress(z)\n",
    "    string = tf.squeeze(string, axis=0)\n",
    "    #Convert z to a tensor\n",
    "    # z = tf.expand_dims(z, 0)\n",
    "    z_tilde, z_likelihoods = entropy_bottleneck(z, training=False)\n",
    "\n",
    "    # To decompress the z_tilde back to avoid the inconsistence error\n",
    "    string_rec = tf.expand_dims(string, 0)\n",
    "    z_tilde = entropy_bottleneck.decompress(string_rec, tf.shape(z)[1:], channels=num_filters)\n",
    "\n",
    "    phi = hyper_synthesis(z_tilde, num_filters)\n",
    "\n",
    "\n",
    "    # REVISION： for Gaussian Mixture Model (GMM), use window-based fast implementation    \n",
    "    #y = tf.clip_by_value(y, -255, 256)\n",
    "    y_hat = tf.round(y)\n",
    "\n",
    "\n",
    "    #tiny_y = tf.placeholder(dtype=tf.float32, shape= [1] + [5] + [5] + [num_filters])\n",
    "    #tiny_phi = tf.placeholder(dtype=tf.float32, shape= [1] + [5] + [5] + [num_filters*2]) \n",
    "    #_, _, y_means, y_variances, y_probs = entropy_parameter(tiny_phi, tiny_y, num_filters, training=False)\n",
    "    #_, _, y_means, y_variances, y_probs, y_probs_lap, y_probs_log, y_probs_mix = entropy_parameter(phi, y, num_filters, training=False)\n",
    "    _, _, y_means, y_variances, y_probs = entropy_parameter(phi, y, num_filters, training=False)\n",
    "    \n",
    "    x_hat = synthesis_transform(y_hat, num_filters)\n",
    "\n",
    "\n",
    "    num_pixels = tf.to_float(tf.reduce_prod(tf.shape(x)[:-1]))\n",
    "    #x_hat = x_hat[0, :tf.shape(x)[1], :tf.shape(x)[2], :]\n",
    "\n",
    "    #op = save_image('temp/temp.png', x_hat)\n",
    "\n",
    "    # Mean squared error across pixels.\n",
    "    x_hat = tf.clip_by_value(x_hat, 0, 1)\n",
    "    x_hat = tf.round(x_hat * 255)\n",
    "    x_ori = x[:, real_height_start:real_height_end, real_width_start:real_width_end, :]\n",
    "    x_hat = x_hat[:, real_height_start:real_height_end, real_width_start:real_width_end, :]\n",
    "    mse = tf.reduce_mean(tf.squared_difference(x_ori, x_hat))\n",
    "\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "      print(tf.trainable_variables())\n",
    "      sess.run(tf.global_variables_initializer())\n",
    "      # Load the latest model checkpoint, get the compressed string and the tensor\n",
    "      # shapes.\n",
    "      latest = tf.train.latest_checkpoint(checkpoint_dir=checkpoint_dir)\n",
    "      \n",
    "      # latest = \"models/model-1399000\" #lambda = 14\n",
    "        \n",
    "      # print(latest)\n",
    "      # tf.train.Saver().restore(sess, save_path=latest)\n",
    "      \n",
    "      \n",
    "      vars_restore = [var for var in tf.global_variables()]\n",
    "      saver_0 = tf.train.Saver(vars_restore)\n",
    "      print(f'Loading learned model from checkpoint {checkpoint_dir}')\n",
    "      saver_0.restore(sess, checkpoint_dir)\n",
    "\n",
    "      \n",
    "      #y_means, y_variances, y_probs\n",
    "      y_means_values, y_variances_values, y_probs_values,string, x_shape, y_shape, num_pixels, y_hat_value, phi_value = \\\n",
    "              sess.run([y_means, y_variances, y_probs, string, tf.shape(x), tf.shape(y), num_pixels, y_hat, phi],feed_dict={images_padded:images_padded_numpy/255.0})\n",
    "      \n",
    "\n",
    "      \n",
    "      minmax = np.maximum(abs(y_hat_value.max()), abs(y_hat_value.min()))\n",
    "      minmax = int(np.maximum(minmax, 1))\n",
    "      #num_symbols = int(2 * minmax + 3)\n",
    "      print(minmax)\n",
    "      #print(num_symbols)\n",
    "      \n",
    "      # Fast implementations by only encoding non-zero channels with 128/8 = 16bytes overhead\n",
    "      flag = np.zeros(y_shape[3], dtype=np.int)\n",
    "      \n",
    "      for ch_idx in range(y_shape[3]):\n",
    "        if np.sum(abs(y_hat_value[:, :,:, ch_idx])) > 0:\n",
    "          flag[ch_idx] = 1\n",
    "\n",
    "      non_zero_idx = np.squeeze(np.where(flag == 1))\n",
    "      \n",
    "      print(\"the zero numbers is {}\".format(num_filters-len(non_zero_idx)))\n",
    "      num = np.packbits(np.reshape(flag, [8, y_shape[3]//8]))\n",
    "\n",
    "      # ============== encode the bits for z===========\n",
    "      if os.path.exists(output):\n",
    "        os.remove(output)\n",
    "\n",
    "      fileobj = open(output, mode='wb')\n",
    "      fileobj.write(np.array(x_shape[1:-1], dtype=np.uint16).tobytes())\n",
    "      fileobj.write(np.array([len(string), minmax], dtype=np.uint16).tobytes())\n",
    "      fileobj.write(np.array(num, dtype=np.uint8).tobytes())\n",
    "      fileobj.write(string)\n",
    "      fileobj.close()\n",
    "\n",
    "\n",
    "\n",
    "      # ============ encode the bits for y ==========\n",
    "      print(\"INFO: start encoding y\")\n",
    "      encoder = RangeEncoder(output[:-4] + '.bin')\n",
    "      samples = np.arange(0, minmax*2+1)\n",
    "      TINY = 1e-10\n",
    "\n",
    "       \n",
    "\n",
    "      kernel_size = 5\n",
    "      pad_size = (kernel_size - 1)//2\n",
    "      \n",
    "      \n",
    "      \n",
    "      padded_y = np.pad(y_hat_value, ((0, 0), (pad_size, pad_size), (pad_size, pad_size), (0, 0)), 'constant',\n",
    "                                 constant_values=((0., 0.), (0., 0.), (0., 0.), (0., 0.)))\n",
    "      padded_phi = np.pad(phi_value, ((0, 0), (pad_size, pad_size), (pad_size, pad_size), (0, 0)), 'constant',\n",
    "                                 constant_values=((0., 0.), (0., 0.), (0., 0.), (0., 0.)))\n",
    "\n",
    "      \n",
    "      for h_idx in range(y_shape[1]):\n",
    "        for w_idx in range(y_shape[2]):          \n",
    "\n",
    "          \n",
    "          extracted_y = padded_y[:, h_idx: h_idx+kernel_size, w_idx:w_idx+kernel_size, :]\n",
    "          extracted_phi = padded_phi[:, h_idx: h_idx+kernel_size, w_idx:w_idx+kernel_size, :]\n",
    "\n",
    "          \n",
    "          # y_means_values, y_variances_values, y_probs_values = \\\n",
    "                          # sess.run([y_means, y_variances, y_probs], \\\n",
    "                                   # feed_dict={images_padded:images_padded_numpy/255.0, tiny_y: extracted_y, tiny_phi: extracted_phi})         \n",
    "                                   \n",
    "          # y_means_values, y_variances_values, y_probs_values, y_probs_lap_values, y_probs_log_values, y_probs_mix_values = \\\n",
    "                          # sess.run([y_means, y_variances, y_probs, y_probs_lap, y_probs_log, y_probs_mix], \\\n",
    "                                   # feed_dict={tiny_y: extracted_y, tiny_phi: extracted_phi})  \n",
    "\n",
    "          \n",
    "          \n",
    "          for i in range(len(non_zero_idx)):\n",
    "            ch_idx = non_zero_idx[i]\n",
    "            \n",
    "            # mu = y_means_values[0, pad_size, pad_size, ch_idx, :] + minmax\n",
    "            # sigma = y_variances_values[0, pad_size, pad_size, ch_idx, :]\n",
    "            # weight = y_probs_values[0, pad_size, pad_size, ch_idx, :]\n",
    "            \n",
    "            # mu = y_means_values[0, pad_size, pad_size, ch_idx, :] + minmax\n",
    "            # sigma = y_variances_values[0, pad_size, pad_size, ch_idx, :]\n",
    "            # weight = y_probs_values[0, pad_size, pad_size, ch_idx, :]\n",
    "            # weight_lap = y_probs_lap_values[0, pad_size, pad_size, ch_idx, :]\n",
    "            # weight_log = y_probs_log_values[0, pad_size, pad_size, ch_idx, :]\n",
    "            # weight_mix = y_probs_mix_values[0, pad_size, pad_size, ch_idx, :]\n",
    "            \n",
    "            mu = y_means_values[0, h_idx, w_idx, ch_idx, :] + minmax\n",
    "            sigma = y_variances_values[0, h_idx, w_idx, ch_idx, :]\n",
    "            weight = y_probs_values[0, h_idx, w_idx, ch_idx, :]\n",
    "            # weight_lap = y_probs_lap_values[0, h_idx, w_idx, ch_idx, :]\n",
    "            # weight_log = y_probs_log_values[0, h_idx, w_idx, ch_idx, :]\n",
    "            # weight_mix = y_probs_mix_values[0, h_idx, w_idx, ch_idx, :]\n",
    "\n",
    "            start00 = time.time()\n",
    "\n",
    "            # Calculate the pmf/cdf            \n",
    "            pmf = (0.5 * (1 + scipy.special.erf((samples + 0.5 - mu[0]) / ((sigma[0] + TINY) * 2 ** 0.5))) - \\\n",
    "                   0.5 * (1 + scipy.special.erf((samples - 0.5 - mu[0]) / ((sigma[0] + TINY) * 2 ** 0.5)))) * weight[0] + \\\n",
    "                  (0.5 * (1 + scipy.special.erf((samples + 0.5 - mu[1]) / ((sigma[1] + TINY) * 2 ** 0.5))) - \\\n",
    "                   0.5 * (1 + scipy.special.erf((samples - 0.5 - mu[1]) / ((sigma[1] + TINY) * 2 ** 0.5)))) * weight[1] +\\\n",
    "                  (0.5 * (1 + scipy.special.erf((samples + 0.5 - mu[2]) / ((sigma[2] + TINY) * 2 ** 0.5))) - \\\n",
    "                   0.5 * (1 + scipy.special.erf((samples - 0.5 - mu[2]) / ((sigma[2] + TINY) * 2 ** 0.5)))) * weight[2]\n",
    "\n",
    "            '''\n",
    "            # Add the tail mass\n",
    "            pmf[0] += 0.5 * (1 + scipy.special.erf(( -0.5 - mu[0]) / ((sigma[0] + TINY) * 2 ** 0.5))) * weight[0] + \\\n",
    "                      0.5 * (1 + scipy.special.erf(( -0.5 - mu[1]) / ((sigma[1] + TINY) * 2 ** 0.5))) * weight[1] + \\\n",
    "                      0.5 * (1 + scipy.special.erf(( -0.5 - mu[2]) / ((sigma[2] + TINY) * 2 ** 0.5))) * weight[2]\n",
    "                      \n",
    "            pmf[-1] += (1. - 0.5 * (1 + scipy.special.erf((minmax*2 + 0.5 - mu[0]) / ((sigma[0] + TINY) * 2 ** 0.5)))) * weight[0] + \\\n",
    "                       (1. - 0.5 * (1 + scipy.special.erf((minmax*2 + 0.5 - mu[1]) / ((sigma[1] + TINY) * 2 ** 0.5)))) * weight[1] + \\\n",
    "                       (1. - 0.5 * (1 + scipy.special.erf((minmax*2 + 0.5 - mu[2]) / ((sigma[2] + TINY) * 2 ** 0.5)))) * weight[2]\n",
    "            '''\n",
    "            \n",
    "            # To avoid the zero-probability            \n",
    "            pmf_clip = np.clip(pmf, 1.0/65536, 1.0)\n",
    "            pmf_clip = np.round(pmf_clip / np.sum(pmf_clip) * 65536)\n",
    "            cdf = list(np.add.accumulate(pmf_clip))\n",
    "            cdf = [0] + [int(i) for i in cdf]\n",
    "                      \n",
    "            symbol = np.int(y_hat_value[0, h_idx, w_idx, ch_idx] + minmax )\n",
    "            encoder.encode([symbol], cdf)\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "      encoder.close()\n",
    "\n",
    "      size_real = os.path.getsize(output) + os.path.getsize(output[:-4] + '.bin')\n",
    "      \n",
    "      bpp_real = (os.path.getsize(output) + os.path.getsize(output[:-4] + '.bin'))* 8 / num_pixels\n",
    "      bpp_side = (os.path.getsize(output))* 8 / num_pixels\n",
    "      \n",
    "\n",
    "      end = time.time()\n",
    "      print(\"Time : {:0.3f}\".format(end-start))\n",
    "\n",
    "      psnr = sess.run(tf.image.psnr(x_hat, x_ori*255, 255),feed_dict={images_padded:images_padded_numpy/255.0})\n",
    "      msssim = sess.run(tf.image.ssim_multiscale(x_hat, x_ori*255, 255),feed_dict={images_padded:images_padded_numpy/255.0})\n",
    "      \n",
    "      print(\"Actual bits per pixel for this image: {:0.4}\".format(bpp_real))\n",
    "      print(\"Side bits per pixel for z: {:0.4}\".format(bpp_side))\n",
    "      print(\"PSNR (dB) : {:0.4}\".format(psnr[0]))\n",
    "      print(\"MS-SSIM : {:0.4}\".format(msssim[0]))\n",
    "      \n",
    "      return bpp_real, (end-start), psnr[0], msssim[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overall_performance(metrics_list):\n",
    "  psnr_rgb_list = []\n",
    "  psnr_y_list = []\n",
    "  psnr_u_list = []\n",
    "  psnr_v_list = []\n",
    "  msssim_rgb_list = []\n",
    "  msssim_y_list = []\n",
    "  bpp_list = []\n",
    "  for metrics_item in metrics_list:\n",
    "    psnr_rgb_list.append(metrics_item[0])\n",
    "    psnr_y_list.append(metrics_item[1][0])\n",
    "    psnr_u_list.append(metrics_item[1][1])\n",
    "    psnr_v_list.append(metrics_item[1][2])\n",
    "    msssim_rgb_list.append(metrics_item[2])\n",
    "    msssim_y_list.append(metrics_item[3])\n",
    "    bpp_list.append(metrics_item[4])\n",
    "  bpp_avg = np.mean(bpp_list)\n",
    "  RGB_MSE_avg = np.mean([255. ** 2 / pow(10, PSNR / 10) for PSNR in psnr_rgb_list])\n",
    "  RGB_PSNR_avg = 10 * np.log10(255. ** 2 / RGB_MSE_avg)\n",
    "  Y_MSE_avg = np.mean([255 ** 2 / pow(10, PSNR / 10) for PSNR in psnr_y_list])\n",
    "  Y_PSNR_avg = 10 * np.log10(255 ** 2 / Y_MSE_avg)\n",
    "  U_MSE_avg = np.mean([255 ** 2 / pow(10, PSNR / 10) for PSNR in psnr_u_list])\n",
    "  U_PSNR_avg = 10 * np.log10(255 ** 2 / U_MSE_avg)\n",
    "  V_MSE_avg = np.mean([255 ** 2 / pow(10, PSNR / 10) for PSNR in psnr_v_list])\n",
    "  V_PSNR_avg = 10 * np.log10(255 ** 2 / V_MSE_avg)\n",
    "  yuv_psnr_avg = 6.0/8.0*Y_PSNR_avg + 1.0/8.0*U_PSNR_avg + 1.0/8.0*V_PSNR_avg\n",
    "  msssim_rgb_avg = np.mean(msssim_rgb_list)\n",
    "  msssim_y_avg = np.mean(msssim_y_list)\n",
    "\n",
    "  print(\"overall performance\")\n",
    "  print(\"RGB PSNR (dB): {:0.2f}\".format(RGB_PSNR_avg))\n",
    "  print(\"YUV444 PSNR (dB): {:0.2f}\".format(yuv_psnr_avg))\n",
    "  print(\"RGB Multiscale SSIM: {:0.4f}\".format(msssim_rgb_avg))\n",
    "  print(\"RGB Multiscale SSIM (dB): {:0.2f}\".format(-10 * np.log10(1 - msssim_rgb_avg)))\n",
    "  print(\"Y Multiscale SSIM: {:0.4f}\".format(msssim_y_avg))\n",
    "  print(\"Y Multiscale SSIM (dB): {:0.2f}\".format(-10 * np.log10(1 - msssim_y_avg)))\n",
    "  print(\"Actual bits per pixel: {:0.4f}\\n\".format(bpp_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def parse_args(argv):\n",
    "#   \"\"\"Parses command line arguments.\"\"\"\n",
    "#   parser = argparse_flags.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "\n",
    "#   # High-level options.\n",
    "#   parser.add_argument(\"--autoregressive\", \"-AR\", action=\"store_true\", help=\"Include autoregressive model for training\")\n",
    "#   parser.add_argument(\"--num_filters\", type=int, default=192, help=\"Number of filters per layer.\")\n",
    "#   parser.add_argument(\"--restore_path\", default=None, help=\"Directory where to load model checkpoints.\")\n",
    "#   parser.add_argument(\"--checkpoint_dir\", default=\"train\", help=\"Directory where to save/load model checkpoints.\")\n",
    "#   parser.add_argument(\"--if_weight\", type=int, default=0.0, help=\"weights\")\n",
    "#   subparsers = parser.add_subparsers(title=\"commands\", dest=\"command\",\n",
    "#       help=\"commands: 'train' loads training data and trains (or continues \"\n",
    "#            \"to train) a new model. 'encode' reads an image file (lossless \"\n",
    "#            \"PNG format) and writes a encoded binary file. 'decode' \"\n",
    "#            \"reads a binary file and reconstructs the image (in PNG format). \"\n",
    "#            \"input and output filenames need to be provided for the latter \"\n",
    "#            \"two options. Invoke '<command> -h' for more information.\")\n",
    "\n",
    "#   # 'train' subcommand.\n",
    "#   train_cmd = subparsers.add_parser(\"train\", formatter_class=argparse.ArgumentDefaultsHelpFormatter, description=\"Trains (or continues to train) a new model.\")\n",
    "#   train_cmd.add_argument(\"--train_root_dir\", default=\"images\", help=\"The root directory of training data, which contains a list of RGB images in PNG format.\")\n",
    "#   train_cmd.add_argument(\"--batchsize\", type=int, default=8, help=\"Batch size for training.\")\n",
    "#   train_cmd.add_argument(\"--patchsize\", type=int, default=256, help=\"Size of image patches for training.\")\n",
    "#   train_cmd.add_argument(\"--lossWeight\", type=float, default=0, dest=\"lossWeight\", help=\"Weight for MSE-SSIM tradeoff.\")\n",
    "#   train_cmd.add_argument(\"--lambda\", type=float, default=0.01, dest=\"lmbda\", help=\"Lambda for rate-distortion tradeoff.\")\n",
    "#   train_cmd.add_argument(\"--last_step\", type=int, default=1500000, help=\"Train up to this number of steps.\")\n",
    "#   train_cmd.add_argument(\"--lr\", type=float, default = 1e-4, help=\"Learning rate [1e-4].\")\n",
    "#   train_cmd.add_argument(\"--lr_scheduling\", \"-lr_sch\", action=\"store_true\", help=\"Enable learning rate scheduling, [enabled] as default\")\n",
    "#   train_cmd.add_argument(\"--preprocess_threads\", type=int, default=16, help=\"Number of CPU threads to use for parallel decoding of training images.\")\n",
    "\n",
    "#   # 'encode' subcommand.\n",
    "#   encode_cmd = subparsers.add_parser(\"encode\", formatter_class=argparse.ArgumentDefaultsHelpFormatter, description=\"Reads a PNG file, encode it, and writes a 'bitstream' file.\")\n",
    "#   # 'decode' subcommand.\n",
    "#   decode_cmd = subparsers.add_parser(\"decode\",formatter_class=argparse.ArgumentDefaultsHelpFormatter,description=\"Reads a 'bitstream' file, reconstructs the image, and writes back a PNG file.\")\n",
    "\n",
    "#   # Arguments for both 'encode' and 'decode'.\n",
    "#   for cmd, ext in ((encode_cmd, \".bitstream\"), (decode_cmd, \".png\")):\n",
    "#     cmd.add_argument(\"input_file\", help=\"Input filename.\")\n",
    "#     cmd.add_argument(\"output_file\", nargs=\"?\", help=\"Output filename (optional). If not provided, appends '{}' to the input filename.\".format(ext))\n",
    "\n",
    "#   # Parse arguments.\n",
    "#   args = parser.parse_args(argv[1:])\n",
    "#   if args.command is None:\n",
    "#     parser.print_usage()\n",
    "#     sys.exit(2)\n",
    "#   return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'2024-01-22 12-03-08.mkv'\n",
      " Asymmetric-Learned-Image-Compression-with-MRSB-IM-and-PQF\n",
      "'Asymmetric Learned Image Compression with.pdf'\n",
      " checkpoint\n",
      "'Image_video compression  (1).docx'\n",
      " kodak\n",
      "'Learned Image Compression with Mixed Transformer-CNN Architectures.pdf'\n",
      "'Learned Image Compression with Mixed Transformer-CNN Architectures Updated.pdf'\n",
      " main.ipynb\n",
      " notes.txt\n",
      " output\n",
      " pywt_updated.ipynb\n",
      " train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bcca/anaconda3/lib/python3.11/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_image = \"kodak/kodim01.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"autoregressive\": False,\n",
    "    \"num_filters\": 192,\n",
    "    \"restore_path\": None,\n",
    "    \"checkpoint_dir\": \"checkpoint/\",\n",
    "    \"if_weight\": 0.0,\n",
    "    \"command\": \"train\", # or encode or decode\n",
    "    \"train_root_dir\": \"kodak/\",\n",
    "    \"batchsize\": 1,\n",
    "    \"patchsize\": 256,\n",
    "    \"lossWeight\": 0,\n",
    "    \"lambda\": 0.01,\n",
    "    \"last_step\": 1500000,\n",
    "    \"lr\": 1e-4,\n",
    "    \"lr_scheduling\": True,\n",
    "    \"preprocess_threads\": 16,\n",
    "    \"input_file\": path_to_image,\n",
    "    \"output_file\": None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = \"2\"\n",
    "    if args[\"command\"] == \"train\":\n",
    "        # train(args)\n",
    "        bpp_real, time,  psnr, msssim = compress(args[\"input_file\"], args[\"output_file\"], args[\"num_filters\"], args[\"checkpoint_dir\"])\n",
    "    elif args[\"command\"] == \"encode\":  # encoding\n",
    "        if not args[\"output_file\"]:\n",
    "            args[\"output_file\"] = args[\"input_file\"] + \".bitstream\"\n",
    "        if os.path.isdir(args[\"input_file\"]):\n",
    "            dirs = os.listdir(args[\"input_file\"])\n",
    "            test_files = []\n",
    "            for dir in dirs:\n",
    "                path = os.path.join(args[\"input_file\"], dir)\n",
    "                if os.path.isdir(path):\n",
    "                    test_files += glob.glob(path + '/*.png')[:6]\n",
    "                if os.path.isfile(path):\n",
    "                    test_files.append(path)\n",
    "            if not test_files:\n",
    "                raise RuntimeError(\n",
    "                    \"No testing images found with glob '{}'.\".format(args[\"input_file\"]))\n",
    "            print(\"Number of images for testing:\", len(test_files))\n",
    "            metrics_list = []\n",
    "            for file_idx in range(len(test_files)):\n",
    "                file = test_files[file_idx]\n",
    "                print(str(file_idx) + \" testing image:\", file)\n",
    "                args[\"input_file\"] = file\n",
    "                image_padded, size = get_image_size(args[\"input_file\"])\n",
    "                metrics = encode(args, image_padded, size)\n",
    "                metrics_list.append(metrics)\n",
    "            overall_performance(metrics_list)\n",
    "        else:\n",
    "            image_padded, size = get_image_size(args[\"input_file\"])\n",
    "            metrics = encode(args, image_padded, size, True)\n",
    "    elif args[\"command\"] == \"decode\":  # decoding\n",
    "        if not args[\"output_file\"]:\n",
    "            args[\"output_file\"] = args[\"input_file\"] + \".png\"\n",
    "        decode(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.experimental.numpy.experimental_enable_numpy_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "height_pad: 512 width_pad: 768\n",
      "the size is 6\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.int64' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m      2\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTF_CPP_MIN_LOG_LEVEL\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcommand\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# train(args)\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m     bpp_real, time,  psnr, msssim \u001b[38;5;241m=\u001b[39m \u001b[43mcompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_file\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_file\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_filters\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcheckpoint_dir\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcommand\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencode\u001b[39m\u001b[38;5;124m\"\u001b[39m:  \u001b[38;5;66;03m# encoding\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_file\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "Input \u001b[0;32mIn [33]\u001b[0m, in \u001b[0;36mcompress\u001b[0;34m(input, output, num_filters, checkpoint_dir)\u001b[0m\n\u001b[1;32m     25\u001b[0m entropy_bottleneck \u001b[38;5;241m=\u001b[39m compressai\u001b[38;5;241m.\u001b[39mentropy_models\u001b[38;5;241m.\u001b[39mEntropyBottleneck(channels\u001b[38;5;241m=\u001b[39mnum_filters)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# entropy_bottleneck = tfc.entropy_models.PowerLawEntropyModel(2, alpha=0.01, bottleneck_dtype=None)\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m string \u001b[38;5;241m=\u001b[39m \u001b[43mentropy_bottleneck\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m string \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39msqueeze(string, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m#Convert z to a tensor\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/compressai/entropy_models/entropy_models.py:561\u001b[0m, in \u001b[0;36mEntropyBottleneck.compress\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompress\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 561\u001b[0m     indexes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_indexes(\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    562\u001b[0m     medians \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_medians()\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m    563\u001b[0m     spatial_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(x\u001b[38;5;241m.\u001b[39msize()) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.int64' object is not callable"
     ]
    }
   ],
   "source": [
    "main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issues being faced in implementation\n",
    "\n",
    "    1. Dependency issues for tensorflow and tensorflow_compression. The code is written in python3 and requires tensorflow 1.14.0 and tensorflow_compression 1.0.0. And, we are using tensorflow 2.3.0 and tensorflow_compression 1.0.0.\n",
    "\n",
    "    2. Issues with code compatibility in windows, therefore shifted the complete environment to Linux Distribution.\n",
    "\n",
    "    3. Some classes have been depreciated, found some of the alternates and substitutes and still working on some of them.\n",
    "\n",
    "    4. Shape related issues for tensors when using substituted versions of tensorflow 2.14. functions and classes.\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/kodak/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/output'\n",
    "checkpoint_dir = '/checkpoint/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def endcoder_main():\n",
    "  eval_bpp_list = []\n",
    "  bpp_real_list = []\n",
    "  time_list = []\n",
    "  psnr_list = []\n",
    "  msssim_list = []\n",
    "  save_image_name_path = checkpoint_dir.split('/')[-2]\n",
    "  print(\"AYUSH\", save_image_name_path)\n",
    "  if not os.path.isdir('./'+save_image_name_path):\n",
    "    os.makedirs('./'+save_image_name_path)\n",
    "    \n",
    "  for image_file in glob(path+'*.png'):\n",
    "    print(image_file[:])\n",
    "    image_name_path = image_file.split('/')[-1]\n",
    "    input = image_file\n",
    "    output = save_image_name_path+'/'+image_name_path + '.npz'\n",
    "    print(input)\n",
    "    print(output)\n",
    "    #output = 'images/'\n",
    "    num_filters = 256\n",
    "    #checkpoint_dir = 'models'    \n",
    "    bpp_real, time,  psnr, msssim = compress(input, output, num_filters, checkpoint_dir)\n",
    "    #decompress(input, output, num_filters, checkpoint_dir)\n",
    "    #eval_bpp_list.append(eval_bpp)\n",
    "    bpp_real_list.append(bpp_real)\n",
    "    time_list.append(time)\n",
    "    psnr_list.append(psnr)\n",
    "    msssim_list.append(msssim)\n",
    "\n",
    "  print(\"\\n\")\n",
    "  print(\"RGB PSNR (dB): {:0.2f}\".format(np.mean(psnr_list)))\n",
    "  print(\"RGB Multiscale SSIM: {:0.4f}\".format(np.mean(msssim_list)))\n",
    "  print(\"RGB Multiscale SSIM (dB): {:0.2f}\".format(-10 * np.log10(1 - np.mean(msssim_list))))\n",
    "  #print(\"Information content in bpp: {:0.4f}\".format(np.mean(eval_bpp_list)))\n",
    "  print(\"Actual bits per pixel: {:0.4f}\".format(np.mean(bpp_real_list)))\n",
    "  print(\"the average time is {:0.4f}\".format(np.mean(time_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_main():\n",
    "  eval_bpp_list = []\n",
    "  bpp_real_list = []\n",
    "  time_list = []\n",
    "  psnr_list = []\n",
    "  msssim_list = []\n",
    "  save_image_name_path = checkpoint_dir.split('/')[-2]\n",
    "  print(save_image_name_path)\n",
    "  if not os.path.isdir('./'+save_image_name_path):\n",
    "    os.makedirs('./'+save_image_name_path)\n",
    "    \n",
    "  for image_file in glob(path+'*.png'):\n",
    "    print(image_file[:])\n",
    "    image_name_path = image_file.split('/')[-1]\n",
    "    input = image_file\n",
    "    output = save_image_name_path+image_name_path + '.npz'\n",
    "    print(input)\n",
    "    print(output)\n",
    "    #output = 'images/'\n",
    "    num_filters = 128\n",
    "    #checkpoint_dir = 'models'    \n",
    "    bpp_real, time,  psnr, msssim = compress(input, output, num_filters, checkpoint_dir)\n",
    "    #decompress(input, output, num_filters, checkpoint_dir)\n",
    "    #eval_bpp_list.append(eval_bpp)\n",
    "    # bpp_real_list.append(bpp_real)\n",
    "    # time_list.append(time)\n",
    "    # psnr_list.append(psnr)\n",
    "    # msssim_list.append(msssim)\n",
    "  print(\"\\n\")\n",
    "  print(\"RGB PSNR (dB): {:0.2f}\".format(np.mean(psnr_list)))\n",
    "  print(\"RGB Multiscale SSIM: {:0.4f}\".format(np.mean(msssim_list)))\n",
    "  print(\"RGB Multiscale SSIM (dB): {:0.2f}\".format(-10 * np.log10(1 - np.mean(msssim_list))))\n",
    "  #print(\"Information content in bpp: {:0.4f}\".format(np.mean(eval_bpp_list)))\n",
    "  print(\"Actual bits per pixel: {:0.4f}\".format(np.mean(bpp_real_list)))\n",
    "  print(\"the average time is {:0.4f}\".format(np.mean(time_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AYUSH checkpoint\n",
      "\n",
      "\n",
      "RGB PSNR (dB): nan\n",
      "RGB Multiscale SSIM: nan\n",
      "RGB Multiscale SSIM (dB): nan\n",
      "Actual bits per pixel: nan\n",
      "the average time is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bcca/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/bcca/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "endcoder_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
